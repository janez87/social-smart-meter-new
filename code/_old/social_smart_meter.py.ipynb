{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Social Smart Meter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from config import instagram_config, twitter_config, facebook_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amsterdam neighborhoods\n",
    "amsterdam = {\n",
    "    'Centrum': {'latitude': '52.372374', 'longitude': '4.898844', 'radius': '1500'},\n",
    "    'Noord': {'latitude': '52.395940', 'longitude': '4.924071', 'radius': '2000'},\n",
    "    'Oost': {'latitude': '', 'longitude': '', 'radius': ''},\n",
    "    'Zuidoost': {'latitude': '52.304499', 'longitude': '4.971431', 'radius': '2000'},\n",
    "    'Zuid': {'latitude': '52.342684', 'longitude': '4.885141', 'radius': '2000'},\n",
    "    'West': {'latitude': '52.388177', 'longitude': '4.862139', 'radius': '1500'},\n",
    "    'Nieuw-West': {'latitude': '52.360300', 'longitude': '4.810984', 'radius': '3000'},\n",
    "    'Westpoort': {'latitude': '52.403051', 'longitude': '4.826776', 'radius': '2000'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a neighborhood\n",
    "neighborhood = amsterdam['Centrum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates\n",
    "latitude = neighborhood['latitude']\n",
    "longitude = neighborhood['longitude']\n",
    "\n",
    "# Radius in meters\n",
    "distance = neighborhood['radius']\n",
    "\n",
    "# Number of posts to retrieve (max = 100)\n",
    "count = 100\n",
    "\n",
    "# Start date\n",
    "min_dt = datetime(2018, 5, 20, 17, 0, 0)\n",
    "min_timestamp = time.mktime(min_dt.timetuple())\n",
    "\n",
    "# End date\n",
    "max_dt = datetime(2018, 5, 20, 18, 0, 0)\n",
    "max_timestamp = time.mktime(max_dt.timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store parameters in object\n",
    "params = {\n",
    "    'lat': latitude,\n",
    "    'lng': longitude,\n",
    "    'distance': distance,  # radius of requested area\n",
    "    'min_timestamp': str(min_timestamp),  # start date\n",
    "    'max_timestamp': str(max_timestamp),  # end date\n",
    "    'count': count,  # number of posts(100 max)\n",
    "    'access_token': instagram_config['access_token']  # your access token\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import connect_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a database to store the data\n",
    "db_name = 'thesis'\n",
    "\n",
    "# Connect to the database\n",
    "db = connect_to_db(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instagram_utils import collect_instagram_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get JSON response via Instagram API, store it in the database, and return the corresponding ObjectId\n",
    "object_id = collect_instagram_data(params, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify whether to save the images or not\n",
    "save_images = True\n",
    "\n",
    "# Process data to store relevant attributes in output collection\n",
    "process_data(object_id, db, save_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the document object differs from the one above, copy value from database\n",
    "object_id = ObjectId(\"5b034a1c7304aaa054bdcd71\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the language of the text using PyPi's language detection library ported from Google's language-detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match Instagram place to Facebook place and determine this place's place topics (or place categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facebook_utils import connect_to_facebook_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request short-term access token and paste it below\n",
    "short_term_access_token = 'EAACEdEose0cBAKmcPzUFRfAPl6CW0msqKwWoereWHlmZBwGZB08MNEZA5qjlwXFU9v05DJgQiG4dQWIrlJoZBoZBdoQdzVW1DPjxSRrkvKK9ELmCVAZAzVNJ8mm6ovuafjMzxIS5ULD3aYqjqM7JwLadqF4ZB4JQlOQ0d9FNEonZBpixjvnCztpOksua9VZBH1T7ZANvgmsv2syQZDZD'\n",
    "\n",
    "# Update facebook config object\n",
    "facebook_config['access_token'] = short_term_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which (access) token type to use:\n",
    "# -'long_term_token' for the long-term access token\n",
    "# - 'user_token' for the short-term user token\n",
    "# - anything else (e.g., '') for the short-term access token\n",
    "token_type = ''\n",
    "\n",
    "# Connect to Facebook API\n",
    "graph = connect_to_facebook_api(token_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare places from current and previous posts to determine the distance traveled between these posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich user profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match Instagram user profile to Twitter one to find a user's home town."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import enrich_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which enrichments to apply to the data\n",
    "enrichments = {\n",
    "    'text_language': False,\n",
    "    'place_categories': True,\n",
    "    'place_distance': False,\n",
    "    'user_home': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the enrichments\n",
    "enrich_data(enrichments, object_id, db, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_utils import merge_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dictionaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionaries import merged_dictionaries\n",
    "# merged_dictionaries['leisure'].append('diving')\n",
    "# merged_dictionaries['mobility'].append('parked')\n",
    "merged_dictionaries['food_consumption'].append('coffee')\n",
    "merged_dictionaries['leisure'].append('coffee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be implemented..\n",
    "\n",
    "# Directory to save trained model\n",
    "# ner_model_dir = './models/ner/'\n",
    "\n",
    "# Train NER model\n",
    "# train_model(ner_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask R-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import get_mrcnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=9.90s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Get pre-trained Mask C-RNN model\n",
    "mrcnn_model, mrcnn_dataset = get_mrcnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any model exported using the export_inference_graph.py tool can be loaded here simply by changing PATH_TO_CKPT to point to a new .pb file. By default we use an \"SSD with Mobilenet\" model here. See the detection model zoo for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import get_tf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_detection_graph, tf_category_index = get_tf_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use other pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('./models/X-152-32x8d-IN5k.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "\n",
    "# path='./models/X-152-32x8d-IN5k.pkl'\n",
    "\n",
    "# weights = pandas.read_pickle(path, compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release of new weight files:\n",
    "\n",
    "# https://github.com/fchollet/deep-learning-models/releases/tag/v0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import classify_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which enrichments to apply to the data\n",
    "classification = {\n",
    "    'text': False,\n",
    "    'image': True,\n",
    "    'place': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't need to use the models:\n",
    "mrcnn_model = None\n",
    "mrcnn_dataset = None\n",
    "tf_detection_graph = None\n",
    "tf_category_index = None\n",
    "\n",
    "# Store models in object and specify whether to run the model or not\n",
    "models = {\n",
    "    'mrcnn': {'run': True, 'model': mrcnn_model, 'dataset': mrcnn_dataset},\n",
    "    'tf': {'run': True, 'detection_graph': tf_detection_graph, 'category_index': tf_category_index}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_data(classification, models, object_id, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "\n",
    "from coco.coco import CocoConfig\n",
    "from coco.coco import CocoDataset\n",
    "\n",
    "from tensor_flow_object_detection import load_model, run_model_on_single_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_id = '1782971715335144481_198080822'\n",
    "image_url = 'https://scontent.cdninstagram.com/vp/814dae94951bd82a92dcc4793aa03648/5B90D2B0/t51.2885-15/s640x640/sh0.08/e35/32237915_2121819221383199_6148507372286377984_n.jpg'\n",
    "image = skimage.io.imread(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/instagram/images/input/1782971715335144481_198080822.jpg\n"
     ]
    }
   ],
   "source": [
    "image_path = '../data/instagram/images/input/{}.jpg'.format(post_id)\n",
    "\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what model to download\n",
    "model_name = 'faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28'    # Alternative: 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "model_file = model_name + '.tar.gz'\n",
    "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "path_to_ckpt = model_name + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "path_to_labels = 'object_detection/data/oid_bbox_trainable_label_map.pbtxt' # Alternative: 'mscoco_label_map.pbtxt'\n",
    "\n",
    "num_classes = 545   # Alternative: 90\n",
    "\n",
    "# Create params object\n",
    "tf_params = {\n",
    "    'model_name': model_name,\n",
    "    'model_file': model_file,\n",
    "    'download_base': download_base,\n",
    "    'path_to_ckpt': path_to_ckpt,\n",
    "    'path_to_labels': path_to_labels,\n",
    "    'num_classes': num_classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tensorflow model\n",
    "tf_detection_graph, tf_category_index = load_model(tf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run model on image\n",
    "output_dict = run_model_on_single_image(image, post_id, tf_detection_graph, tf_category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_detections': 3, 'detection_boxes': array([[0.06364858, 0.06219246, 0.88002086, 0.7775232 ],\n",
      "       [0.11871229, 0.03846986, 0.51375073, 0.39425084],\n",
      "       [0.        , 0.00218953, 0.7550753 , 0.6042471 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32), 'detection_scores': array([0.7235652, 0.699169 , 0.5480721, 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
      "       0.       , 0.       , 0.       , 0.       ], dtype=float32), 'detection_classes': array([43, 16, 43,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "      dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "print(output_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
